{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f8206d-b409-4e0e-a952-a36c67093440",
   "metadata": {},
   "outputs": [],
   "source": [
    "owner = 'team-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723c5f71-1338-4cf9-92ca-db77af750989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polaris as po\n",
    "import datamol as dm\n",
    "import numpy as np\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7122c9-055c-4221-b946-8d19fc081178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-21 16:23:49.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n",
      "\u001b[32m2024-06-21 16:23:49.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 3)\n"
     ]
    }
   ],
   "source": [
    "benchmark = po.load_benchmark(\"polaris/pkis1-kit-wt-mut-c-1\")\n",
    "train, test = benchmark.get_train_test_split(featurization_fn=dm.to_fp)\n",
    "#train, test = benchmark.get_train_test_split()\n",
    "\n",
    "ys = train.y\n",
    "ys = np.stack([ys[target] for target in benchmark.target_cols], axis=1)\n",
    "mask = ~np.any(np.isnan(ys), axis=1)\n",
    "mask.sum()\n",
    "\n",
    "X_train = train.X[mask]\n",
    "y_train = ys[mask]\n",
    "\n",
    "print(y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5141bf08-b539-4a55-9309-27beee1f5718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-21 16:23:50.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n",
      "\u001b[32m2024-06-21 16:23:50.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.0.0) is different from the currently installed version of Polaris (dev).\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "        \n",
    "from imblearn.over_sampling import SMOTE\n",
    "import polaris as po\n",
    "import datamol as dm\n",
    "import numpy as np\n",
    "\n",
    "mapping = {\n",
    " (0.0, 0.0, 0.0): 0,\n",
    " (1.0, 0.0, 0.0): 1,\n",
    " (1.0, 0.0, 1.0): 2,\n",
    " (1.0, 1.0, 0.0): 3,\n",
    " (1.0, 1.0, 1.0): 4,\n",
    "}\n",
    "inv_mapping = {v: k for k, v in mapping.items()}\n",
    "\n",
    "# load dataset\n",
    "benchmark = po.load_benchmark(\"polaris/pkis1-kit-wt-mut-c-1\")\n",
    "# use ECFP fingerprint\n",
    "train, test = benchmark.get_train_test_split(featurization_fn=partial(dm.to_fp, fp_type='ecfp'))\n",
    "\n",
    "# define order of target values\n",
    "target_order = ['CLASS_KIT', 'CLASS_KIT_(T6701_mutant)', 'CLASS_KIT_(V560G_mutant)']\n",
    "\n",
    "# reshape the y values for convenience\n",
    "ys = train.y\n",
    "ys = np.stack([ys[target] for target in target_order], axis=1)\n",
    "ys.shape\n",
    "\n",
    "# remove the rows with NaN values\n",
    "mask = ~np.any(np.isnan(ys), axis=1)\n",
    "mask.sum()\n",
    "X = train.X[mask]\n",
    "ys = ys[mask]\n",
    "\n",
    "ys_scalarized = [tuple(item) for item in ys]\n",
    "ys_scalarized = [mapping[item] for i, item in enumerate(ys_scalarized)]\n",
    "\n",
    "X_train, y_resampled = SMOTE(k_neighbors=2).fit_resample(X, ys_scalarized)\n",
    "y_train = [inv_mapping[item] for i, item in enumerate(y_resampled)]\n",
    "\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e248af1-aea9-404d-a654-77abb43bfd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from bayes_opt import BayesianOptimization\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer, average_precision_score\n",
    "\n",
    "def get_param(optimizer):    \n",
    "    best_params = optimizer.max['params']\n",
    "    best_params['input_dim'] = int(best_params['input_dim'])\n",
    "    best_params['learning_rate'] = int(best_params['learning_rate'])\n",
    "    best_params['dropout_rate'] = int(best_params['dropout_rate'])\n",
    "    best_params['num_neurons_layer1'] = int(best_params['num_neurons_layer1'])\n",
    "    best_params['num_neurons_layer2'] = int(best_params['num_neurons_layer2'])\n",
    "    return best_params\n",
    "\n",
    "def opt_multi_targets(param_bounds):\n",
    "\n",
    "\n",
    "    # benchmark = po.load_benchmark(\"polaris/pkis1-kit-wt-mut-c-1\")\n",
    "    # train, test = benchmark.get_train_test_split(featurization_fn=dm.to_fp)\n",
    "    # #train, test = benchmark.get_train_test_split()\n",
    "    \n",
    "    # ys = train.y\n",
    "    # ys = np.stack([ys[target] for target in benchmark.target_cols], axis=1)\n",
    "    # mask = ~np.any(np.isnan(ys), axis=1)\n",
    "    # mask.sum()\n",
    "    \n",
    "    # X_train = train.X[mask]\n",
    "    # y_train = ys[mask]\n",
    "\n",
    "    X_train, y_resampled = SMOTE(k_neighbors=2).fit_resample(X, ys_scalarized)\n",
    "    y_train = [inv_mapping[item] for i, item in enumerate(y_resampled)]\n",
    "    y_train = np.array(y_train)\n",
    "  \n",
    "    def create_model(input_dim, learning_rate, dropout_rate, num_neurons_layer1, num_neurons_layer2):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(int(num_neurons_layer1), input_dim=input_dim, activation='relu', kernel_regularizer='l2'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(int(num_neurons_layer2), activation='relu', kernel_regularizer='l2'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(3, activation='sigmoid'))  # 3 output classes\n",
    "        model.compile(loss='bce', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def optimize_model(learning_rate, dropout_rate, num_neurons_layer1, num_neurons_layer2):\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        accuracies = []\n",
    "    \n",
    "        for train_index, val_index in kfold.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "            \n",
    "            model = create_model(learning_rate, dropout_rate, num_neurons_layer1, num_neurons_layer2)\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            \n",
    "            model.fit(X_train_fold, y_train_fold, epochs=100, batch_size=16, verbose=0, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping])\n",
    "            _, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        return np.mean(accuracies)\n",
    "\n",
    "    def objective(input_dim, num_neurons_layer1, num_neurons_layer2, dropout_rate, learning_rate):\n",
    "        dnn = KerasClassifier(model=create_model, \n",
    "                              input_dim = int(input_dim),\n",
    "                              learning_rate=learning_rate, \n",
    "                              dropout_rate=dropout_rate, \n",
    "                              num_neurons_layer1=num_neurons_layer1, \n",
    "                              num_neurons_layer2=num_neurons_layer2,\n",
    "                              epochs=50, \n",
    "                              batch_size=16, \n",
    "                              verbose=0)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('pca', PCA(int(input_dim))),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('dnn', dnn)\n",
    "        ])\n",
    "        \n",
    "        # Use K-Fold cross-validation\n",
    "        kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Evaluate the model using cross-validation\n",
    "        scoring = make_scorer(average_precision_score, needs_proba=True)\n",
    "        \n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        return cv_scores.mean()\n",
    "\n",
    "    \n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=objective,\n",
    "        pbounds=param_bounds,\n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    optimizer.maximize(init_points=5, n_iter=15)\n",
    "\n",
    "    best_params = optimizer.max['params']\n",
    "    print(\"Best parameters: \", best_params)\n",
    "    \n",
    "    # Train the final model with the best parameters\n",
    "    # final_model = create_model(best_params['learning_rate'], best_params['dropout_rate'], best_params['num_neurons_layer1'], best_params['num_neurons_layer2'])\n",
    "    # early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    # final_model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=2, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "    # dnn = KerasClassifier(model=create_model, \n",
    "    #                       input_dim = best_params['input_dim'],\n",
    "    #                       learning_rate=best_params['learning_rate'], \n",
    "    #                       dropout_rate=best_params['dropout_rate'], \n",
    "    #                       num_neurons_layer1=best_params['num_neurons_layer1'], \n",
    "    #                       num_neurons_layer2=best_params['num_neurons_layer2'],\n",
    "    #                       epochs=50, \n",
    "    #                       batch_size=16, \n",
    "    #                       verbose=0)\n",
    "    \n",
    "    \n",
    "    #dnn.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the final model  \n",
    "    \n",
    "\n",
    "    # optimizer = BayesianOptimization(f=objective, pbounds=param_bounds, random_state=42, verbose = 2)\n",
    "    \n",
    "    # optimizer.maximize(init_points=5, n_iter=5)\n",
    "    \n",
    "    # best_params = get_param(optimizer)\n",
    "\n",
    "    # best_dnn = KerasClassifier(build_fn=create_model, \n",
    "    #                            num_neurons_layer1=best_params['num_neurons_layer1'], \n",
    "    #                            num_neurons_layer2=best_params['num_neurons_layer2'], \n",
    "    #                            dropout_rate=best_params['dropout_rate'], \n",
    "    #                            learning_rate=best_params['learning_rate'],\n",
    "    #                            epochs=50, \n",
    "    #                            batch_size=16, \n",
    "    #                            verbose=2)\n",
    "\n",
    "    \n",
    "    # # Evaluate the final model\n",
    "    # loss, accuracy = best_pipeline.evaluate(X_test, y_test, verbose=2)\n",
    "    # print(f\"Final model accuracy: {accuracy}\")\n",
    "    \n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dad46db-66d8-4279-8349-2c745764afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | dropou... | input_dim | learni... | num_ne... | num_ne... |\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9982   \u001b[0m | \u001b[0m0.1124   \u001b[0m | \u001b[0m95.56    \u001b[0m | \u001b[0m0.007347 \u001b[0m | \u001b[0m63.88    \u001b[0m | \u001b[0m24.04    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.9927   \u001b[0m | \u001b[0m0.0468   \u001b[0m | \u001b[0m15.23    \u001b[0m | \u001b[0m0.008675 \u001b[0m | \u001b[0m64.1     \u001b[0m | \u001b[0m73.73    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.9976   \u001b[0m | \u001b[0m0.006175 \u001b[0m | \u001b[0m97.29    \u001b[0m | \u001b[0m0.008341 \u001b[0m | \u001b[0m29.11    \u001b[0m | \u001b[0m26.36    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.998    \u001b[0m | \u001b[0m0.05502  \u001b[0m | \u001b[0m37.38    \u001b[0m | \u001b[0m0.005295 \u001b[0m | \u001b[0m48.88    \u001b[0m | \u001b[0m36.21    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.9973   \u001b[0m | \u001b[0m0.1836   \u001b[0m | \u001b[0m22.55    \u001b[0m | \u001b[0m0.002992 \u001b[0m | \u001b[0m42.97    \u001b[0m | \u001b[0m51.05    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9981   \u001b[0m | \u001b[0m0.165    \u001b[0m | \u001b[0m68.57    \u001b[0m | \u001b[0m0.008151 \u001b[0m | \u001b[0m49.08    \u001b[0m | \u001b[0m21.21    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.9971   \u001b[0m | \u001b[0m0.2168   \u001b[0m | \u001b[0m96.09    \u001b[0m | \u001b[0m0.008915 \u001b[0m | \u001b[0m63.77    \u001b[0m | \u001b[0m22.54    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m8        \u001b[0m | \u001b[95m0.9986   \u001b[0m | \u001b[95m0.0915   \u001b[0m | \u001b[95m92.81    \u001b[0m | \u001b[95m0.001439 \u001b[0m | \u001b[95m62.25    \u001b[0m | \u001b[95m27.71    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9986   \u001b[0m | \u001b[0m0.05532  \u001b[0m | \u001b[0m89.9     \u001b[0m | \u001b[0m0.008036 \u001b[0m | \u001b[0m69.4     \u001b[0m | \u001b[0m27.31    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m10       \u001b[0m | \u001b[95m0.9992   \u001b[0m | \u001b[95m0.006139 \u001b[0m | \u001b[95m94.08    \u001b[0m | \u001b[95m0.007932 \u001b[0m | \u001b[95m69.9     \u001b[0m | \u001b[95m31.87    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.9975   \u001b[0m | \u001b[0m0.2467   \u001b[0m | \u001b[0m98.78    \u001b[0m | \u001b[0m0.001993 \u001b[0m | \u001b[0m69.24    \u001b[0m | \u001b[0m27.98    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.9987   \u001b[0m | \u001b[0m0.2879   \u001b[0m | \u001b[0m93.44    \u001b[0m | \u001b[0m0.002882 \u001b[0m | \u001b[0m66.28    \u001b[0m | \u001b[0m35.59    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.9986   \u001b[0m | \u001b[0m0.06329  \u001b[0m | \u001b[0m93.61    \u001b[0m | \u001b[0m0.007194 \u001b[0m | \u001b[0m75.03    \u001b[0m | \u001b[0m39.24    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.9978   \u001b[0m | \u001b[0m0.08322  \u001b[0m | \u001b[0m88.51    \u001b[0m | \u001b[0m0.007567 \u001b[0m | \u001b[0m73.57    \u001b[0m | \u001b[0m34.57    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.9974   \u001b[0m | \u001b[0m0.282    \u001b[0m | \u001b[0m97.53    \u001b[0m | \u001b[0m0.009211 \u001b[0m | \u001b[0m70.51    \u001b[0m | \u001b[0m42.11    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.998    \u001b[0m | \u001b[0m0.1711   \u001b[0m | \u001b[0m97.97    \u001b[0m | \u001b[0m0.008553 \u001b[0m | \u001b[0m61.68    \u001b[0m | \u001b[0m31.37    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718987335.448265  271530 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_16', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.9957   \u001b[0m | \u001b[0m0.05666  \u001b[0m | \u001b[0m95.44    \u001b[0m | \u001b[0m0.002966 \u001b[0m | \u001b[0m80.67    \u001b[0m | \u001b[0m33.39    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.9973   \u001b[0m | \u001b[0m0.1612   \u001b[0m | \u001b[0m86.28    \u001b[0m | \u001b[0m0.008601 \u001b[0m | \u001b[0m62.28    \u001b[0m | \u001b[0m36.32    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.9989   \u001b[0m | \u001b[0m0.2639   \u001b[0m | \u001b[0m90.79    \u001b[0m | \u001b[0m0.003398 \u001b[0m | \u001b[0m75.62    \u001b[0m | \u001b[0m45.5     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.9978   \u001b[0m | \u001b[0m0.2363   \u001b[0m | \u001b[0m84.76    \u001b[0m | \u001b[0m0.003042 \u001b[0m | \u001b[0m73.91    \u001b[0m | \u001b[0m43.83    \u001b[0m |\n",
      "=====================================================================================\n",
      "Best parameters:  {'dropout_rate': 0.006139492719022066, 'input_dim': 94.08157339950867, 'learning_rate': 0.00793215140153552, 'num_neurons_layer1': 69.90478437564767, 'num_neurons_layer2': 31.874906370880705}\n"
     ]
    }
   ],
   "source": [
    "param_bounds = {\n",
    "    'learning_rate': (0.0001, 0.01),\n",
    "    'input_dim': (10, 100),\n",
    "    'dropout_rate': (0.0, 0.3),\n",
    "    'num_neurons_layer1': (10, 100),  # Layer 1 neurons\n",
    "    'num_neurons_layer2': (10, 100)   # Layer 2 neurons\n",
    "}\n",
    "\n",
    "best_params = opt_multi_targets(param_bounds = param_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a650d95a-9c67-4d8e-ba6b-8382841bc304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/pydantic/main.py:347: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `str` but got `dict` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_dim, learning_rate, dropout_rate, num_neurons_layer1, num_neurons_layer2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(num_neurons_layer1), input_dim=input_dim, activation='relu', kernel_regularizer='l2'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(int(num_neurons_layer2), activation='relu', kernel_regularizer='l2'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation='sigmoid'))  # 3 output classes\n",
    "    model.compile(loss='bce', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "dnn = KerasClassifier(model=create_model, \n",
    "                      input_dim = int(best_params['input_dim']),\n",
    "                      learning_rate=best_params['learning_rate'], \n",
    "                      dropout_rate=best_params['dropout_rate'], \n",
    "                      num_neurons_layer1=best_params['num_neurons_layer1'], \n",
    "                      num_neurons_layer2=best_params['num_neurons_layer2'],\n",
    "                      epochs=50, \n",
    "                      batch_size=16, \n",
    "                      verbose=0)\n",
    "\n",
    "pca = PCA(n_components = int(best_params['input_dim']))\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(test.X)\n",
    "\n",
    "StandardScaler()\n",
    "\n",
    "dnn.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = dnn.predict(X_test_pca)\n",
    "#print(y_pred)\n",
    "\n",
    "y_prob = dnn.predict_proba(X_test_pca)\n",
    "#y_prob = np.stack(y_prob, axis=1)\n",
    "#print(y_prob)\n",
    "\n",
    "y_pred_multi = {k: y_pred[:, idx] for idx, k in enumerate(benchmark.target_cols)}\n",
    "y_prob_multi = {k: y_prob[:, idx] for idx, k in enumerate(benchmark.target_cols)}\n",
    "\n",
    "results_multi = benchmark.evaluate(y_pred=y_pred_multi, y_prob=y_prob_multi)\n",
    "\n",
    "\n",
    "results_multi.name = \"dnn_multi_augm_pca\"\n",
    "results_multi.description = best_params\n",
    "results_multi.to_json('dnn_multi_augm_pca.json')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1008390-fb30-486b-b00c-0c7af0b94f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><tr><th>name</th><td>dnn_multi_augm_pca</td></tr><tr><th>description</th><td><table border=\"1\"><tr><th>dropout_rate</th><td>0.006139492719022066</td></tr><tr><th>input_dim</th><td>94.08157339950867</td></tr><tr><th>learning_rate</th><td>0.00793215140153552</td></tr><tr><th>num_neurons_layer1</th><td>69.90478437564767</td></tr><tr><th>num_neurons_layer2</th><td>31.874906370880705</td></tr></table></td></tr><tr><th>tags</th><td></td></tr><tr><th>user_attributes</th><td></td></tr><tr><th>owner</th><td>None</td></tr><tr><th>polaris_version</th><td>dev</td></tr><tr><th>benchmark_name</th><td>pkis1-kit-wt-mut-c-1</td></tr><tr><th>benchmark_owner</th><td><table border=\"1\"><tr><th>slug</th><td>polaris</td></tr><tr><th>external_id</th><td>org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu</td></tr><tr><th>type</th><td>organization</td></tr></table></td></tr><tr><th>github_url</th><td>None</td></tr><tr><th>paper_url</th><td>None</td></tr><tr><th>contributors</th><td>None</td></tr><tr><th>artifact_id</th><td>None</td></tr><tr><th>benchmark_artifact_id</th><td>polaris/pkis1-kit-wt-mut-c-1</td></tr><tr><th>results</th><td><table border=\"1\"><thead><tr><th>Test set</th><th>Target label</th><th>Metric</th><th>Score</th></tr></thead><tbody><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>accuracy</td><td>0.8390804598</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>accuracy</td><td>0.8620689655</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>accuracy</td><td>0.6206896552</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>f1</td><td>0.0</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>f1</td><td>0.0</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>f1</td><td>0.0</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>roc_auc</td><td>0.614481409</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>roc_auc</td><td>0.5211111111</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>roc_auc</td><td>0.6094276094</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>pr_auc</td><td>0.2544169887</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>pr_auc</td><td>0.194748974</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>pr_auc</td><td>0.4527244967</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>mcc</td><td>0.0</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>mcc</td><td>0.0</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>mcc</td><td>0.0</td></tr><tr><td>test</td><td>CLASS_KIT_(T6701_mutant)</td><td>cohen_kappa</td><td>0.0</td></tr><tr><td>test</td><td>CLASS_KIT_(V560G_mutant)</td><td>cohen_kappa</td><td>0.0</td></tr><tr><td>test</td><td>CLASS_KIT</td><td>cohen_kappa</td><td>0.0</td></tr></tbody></table></td></tr></table>"
      ],
      "text/plain": [
       "{\n",
       "  \"name\": \"dnn_multi_augm_pca\",\n",
       "  \"description\": {\n",
       "    \"dropout_rate\": 0.006139492719022066,\n",
       "    \"input_dim\": 94.08157339950867,\n",
       "    \"learning_rate\": 0.00793215140153552,\n",
       "    \"num_neurons_layer1\": 69.90478437564767,\n",
       "    \"num_neurons_layer2\": 31.874906370880705\n",
       "  },\n",
       "  \"tags\": [],\n",
       "  \"user_attributes\": {},\n",
       "  \"owner\": null,\n",
       "  \"polaris_version\": \"dev\",\n",
       "  \"benchmark_name\": \"pkis1-kit-wt-mut-c-1\",\n",
       "  \"benchmark_owner\": {\n",
       "    \"slug\": \"polaris\",\n",
       "    \"external_id\": \"org_2gtoaJIVrgRqiIR8Qm5BnpFCbxu\",\n",
       "    \"type\": \"organization\"\n",
       "  },\n",
       "  \"github_url\": null,\n",
       "  \"paper_url\": null,\n",
       "  \"contributors\": null,\n",
       "  \"artifact_id\": null,\n",
       "  \"benchmark_artifact_id\": \"polaris/pkis1-kit-wt-mut-c-1\",\n",
       "  \"results\": [\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"accuracy\",\n",
       "      \"Score\": 0.8390804598\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"accuracy\",\n",
       "      \"Score\": 0.8620689655\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"accuracy\",\n",
       "      \"Score\": 0.6206896552\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"f1\",\n",
       "      \"Score\": 0.0\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"f1\",\n",
       "      \"Score\": 0.0\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"f1\",\n",
       "      \"Score\": 0.0\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"roc_auc\",\n",
       "      \"Score\": 0.614481409\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"roc_auc\",\n",
       "      \"Score\": 0.5211111111\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"roc_auc\",\n",
       "      \"Score\": 0.6094276094\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"pr_auc\",\n",
       "      \"Score\": 0.2544169887\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"pr_auc\",\n",
       "      \"Score\": 0.194748974\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"pr_auc\",\n",
       "      \"Score\": 0.4527244967\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"mcc\",\n",
       "      \"Score\": 0.0\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"mcc\",\n",
       "      \"Score\": 0.0\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"mcc\",\n",
       "      \"Score\": 0.0\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(T6701_mutant)\",\n",
       "      \"Metric\": \"cohen_kappa\",\n",
       "      \"Score\": 0.0\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT_(V560G_mutant)\",\n",
       "      \"Metric\": \"cohen_kappa\",\n",
       "      \"Score\": 0.0\n",
       "    },\n",
       "    {\n",
       "      \"Test set\": \"test\",\n",
       "      \"Target label\": \"CLASS_KIT\",\n",
       "      \"Metric\": \"cohen_kappa\",\n",
       "      \"Score\": 0.0\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c47b4ab9-dbad-47fc-b7d7-2882d757a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params =  {'dropout_rate': 0.0013434256997184812, 'learning_rate': 0.0004996258264765169, 'num_neurons_layer1': 51.9807344803538, 'num_neurons_layer2': 41.68970050564931}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5724fcd2-bc5a-4f7d-b6c1-019f770d19d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9715447154471545\n"
     ]
    }
   ],
   "source": [
    "X_train, y_resampled = SMOTE(k_neighbors=2).fit_resample(X, ys_scalarized)\n",
    "y_train = [inv_mapping[item] for i, item in enumerate(y_resampled)]\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "def create_model(input_dim, learning_rate, dropout_rate, num_neurons_layer1, num_neurons_layer2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(num_neurons_layer1), input_dim=input_dim, activation='relu', kernel_regularizer='l2'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(int(num_neurons_layer2), activation='relu', kernel_regularizer='l2'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation='sigmoid'))  # 3 output classes\n",
    "    model.compile(loss='bce', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_dim = 100\n",
    "dnn = KerasClassifier(model=create_model, \n",
    "                      input_dim = input_dim,\n",
    "                      learning_rate=best_params['learning_rate'], \n",
    "                      dropout_rate=best_params['dropout_rate'], \n",
    "                      num_neurons_layer1=best_params['num_neurons_layer1'], \n",
    "                      num_neurons_layer2=best_params['num_neurons_layer2'],\n",
    "                      epochs=50, \n",
    "                      batch_size=16, \n",
    "                      verbose=0)\n",
    "\n",
    "pca = PCA(n_components = input_dim)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "            ('pca', pca),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('dnn', dnn)\n",
    "        ])\n",
    "# Use K-Fold cross-validation\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "print(cv_scores.mean())\n",
    "#dnn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b50602b8-839a-4ea2-bcfd-9ef4428493a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b264170c-f512-462e-8245-17f36577b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_216\" is incompatible with the layer: expected axis -1 of input shape to have value 2048, but received input with shape (None, 100)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 100), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_219\" is incompatible with the layer: expected axis -1 of input shape to have value 2048, but received input with shape (None, 100)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 100), dtype=float32)\n  • training=True\n  • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m kfold \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Evaluate the model using cross-validation\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(cv_scores\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[0;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 2 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_216\" is incompatible with the layer: expected axis -1 of input shape to have value 2048, but received input with shape (None, 100)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 100), dtype=float32)\n  • training=True\n  • mask=None\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/sklearn/pipeline.py\", line 476, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 938, in _fit\n    self._fit_keras_model(\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/ubuntu/micromamba/envs/moml-ilya/lib/python3.11/site-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_219\" is incompatible with the layer: expected axis -1 of input shape to have value 2048, but received input with shape (None, 100)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 100), dtype=float32)\n  • training=True\n  • mask=None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a838c-7feb-4459-be4f-5151bca535a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
